## ğŸ§‘â€ğŸ’» Full User Story â€“ Amine Uses MoviesYouDidntWatch.com

---

### ğŸ§© Scene 1 â€“ Arrival: Hero Page

Amine opens `MoviesYouDidntWatch.com` on his browser.

- The **Hero page** loads instantly.
- It welcomes him in English by default.
- At the center: he sees two big buttons â†’ `Login` and `Register`.
- At the top-right corner, he notices a language switch: `FranÃ§ais ğŸ‡«ğŸ‡· / English ğŸ‡¬ğŸ‡§`.
- He clicks `FranÃ§ais` â€” the whole UI switches to French.
- He clicks `Register`.

---

### ğŸ§© Scene 2 â€“ Registering an Account

- The `Register` page opens.
- Fields: Name, Email, Password.
- Amine enters:
  - Name: `Amine`
  - Email: `amine@gmail.com`
  - Password: `12345678`
- He clicks `Submit`.
- Request is sent to `POST /auth/register`.
- âœ… Backend hashes the password, stores the user.
- ğŸ‰ He sees: "Account created! Please log in."

---

### ğŸ§© Scene 3 â€“ Logging In

- Heâ€™s redirected to `Login` page.
- Enters:
  - Email: `amine@gmail.com`
  - Password: `12345678`
- Clicks `Login`.
- Request sent to `POST /auth/login`.
- âœ… JWT is returned.
- ğŸ§  Frontend stores JWT in memory (or localStorage).
- User is redirected to: `/app`

---

### ğŸ§© Scene 4 â€“ Main App (`/app`)

- The screen is split:
  - **Left side** â†’ A welcome message from the chatbot:
    > "ğŸ¬ Welcome, Amine! Looking for your next movie?"
  - **Right side** â†’ Empty movie grid (waiting for a query).

- He types into the Chat:
  > â€œShow me a sci-fi movie with good reviewsâ€

---

### ğŸ§© Scene 5 â€“ Backend Processing Begins

**Request goes to:** `POST /chat`  
Payload:
```json
{
  "session_id": "12ae3f1b-89f2-4c6e-bb1e-b8f6f4a231bd",
  "message": "Show me a sci-fi movie with good reviews"
}
```
Auth: JWT token attached

---



#### ğŸ”§ Backend flow (inside `/chat`):

1. âœ… **JWT is decoded**, and `user_id` is extracted.

2. âœ… **Session check**:
   - If `session_id` exists â†’ retrieve it (used for multi-turn context).
   - If it doesnâ€™t exist or is invalid â†’ raise an error or create a new session.

---

3. ğŸ§  **LLM is called** using the userâ€™s message.  
Function: `get_llm_completion(message: str) â†’ str`  
The prompt uses a predefined template, like:

```
You are a movie assistant. Ask the user what kind of movie they'd like to watch. You can suggest genres, ratings, release dates, or any preferences.

When the user provides filters, you MUST append a new line to your message starting with:

[filters_requested] genre: ..., min_release_date: ..., min_imdb_rating: ..., language: ...

Only use this format if you're confident the user provided filters.
```

---
4. ğŸ§¾ **LLM response is parsed**:
   - We split the response by lines and check if **the last line** starts with `[filters_requested]`.
   - âœ… If the flag exists:
     - The rest of the line is parsed into a `MovieSearchFilter` object.
     - The movies are fetched via `get_filtered_movies()`.
     - A `[movie_context]` assistant message is created *silently*, containing:
       ```
       [movie_context]
       1. Interstellar â€“ IMDb 8.6 â€“ A team of explorers travels through a wormhole...
       2. Arrival â€“ IMDb 7.9 â€“ A linguist helps humans communicate with aliens...
       ```
     - This message is **injected into the conversation**, but **not returned to the frontend** (itâ€™s backend-only memory).
     - The **chat response includes**:
       - `llm_response` (the message before the `[filters_requested]` line)
       - `movies` (filtered list)
       - `update_movies = True`
   - âŒ If no `[filters_requested]` flag is present:
     - We only return the `llm_response` (entire message)
     - Set `movies = []`
     - Set `update_movies = False`



5. âœ‚ï¸ **Conversation Pruning â€“ Send Only Relevant Context to the LLM**

To prevent the LLM from being overwhelmed by long history or outdated movie suggestions, we apply **context pruning** *only when preparing the messages sent to the LLM*.  
**Important**: We never delete messages from the database â€” only from the current payload.

---

### ğŸ§  Strategy:

- When a new `[filters_requested]` flag is detected:
  1. Fetch a new movie list.
  2. Inject a `[movie_context]` assistant message (containing movie summaries).
  3. **Before sending to the LLM**:
     - Look for the **last `[movie_context]`** message in the `messages` list.
     - **Only include messages from after that point onward** (i.e., drop earlier turns from the LLM payload).
     - Append the new `[movie_context]` at the end of this filtered list.
  4. This trimmed list is what gets sent to `get_llm_completion()`.

---

6. ğŸ” **Return `ChatResponse`** to frontend:
```json
{
  "message": "Sure! Would you like something more action-packed or romantic?",
  "movies": [],
  "update_movies": false
}
```
or:
```json
{
  "message": "How about a great comedy? Here's what I found for you:",
  "movies": [ ...MovieCard list... ],
  "update_movies": true
}
```